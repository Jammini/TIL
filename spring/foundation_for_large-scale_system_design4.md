# 4장 처리율 제한 장치의 설계

네트워크 시스템에서 처리율 제한 장치는 클라이언트 또는 서비스가 보내는 트래픽의 처리율을 제어하기 위한 장이치다. HTTP를 예로 몇가지 사례는 다음과 같다.

- 사용자는 초당 2회 이상 새 글을 올릴 수 없다.
- 같은 IP주소로는 하루에 10개 이상의 계정을 생성할 수 없다.
- 같은 디바이스로는 주당 5회 이상 리워드를 요청할 수 없다.

### API 처리율 제한 장치의 장점

- DoS(Denial of Service) 공격에 의한 자원 고갈을 방지
    - 2시간 동안 300개의 트윗만 올릴 수 있음.
    - 구글 독스 API는 사용자당 분당 300회의 read 요청만 허용.
- 비용 절감
    - 제 3자(third-party) API에 사용료를 지불하고 있는 회사에게 유용함.
    - 신용 확인, 신용카드 결제, 건강 상태 확인하기 위해 호출하는 API에 대한 과금에 대한 횟수를 줄임.
- 서버 과부하를 막음
    - 봇(bot)에서 오는 트래픽이나 사용자의 잘못된 이용패턴으로 유발된 트래픽을 걸러냄.

## 1단계 문제 이해 및 설계 범위 확정

### 요구사항 파악

- 설정된 처리율을 초과하는 요청은 정확하게 제한한다
- 낮은 응답시간 : 이 처리율 제한 장치는 HTTP 응답시간에 나쁜 영향을 주어서는 곤란하다.
- 적은 메모리
- 분산형 처리율 제한 : 하나의 처리율 제한 장치를 여러 서버나 프로세스에 공유할 수 있어야 한다.
- 예외 처리 : 요청이 제한되었을 때는 그 사실을 사용자에게 분명하게 보여주어야 한다.
- 높은 결함 감내성 : 제한 장치에 장애가 생기더라도 전체 시스템에 영향을 주어서는 안 된다.

## 2단계 개략적 설계안 제시 및 동의 구하기

### 처리율 제한 장치는 어디에 둘 것인가?

- 클라이언트 측 : 클라이언트 요청은 쉽게 위변조가 가능하기에 안정적이지 못하다.
- 서버 측
1. API 서버

<img width="756" alt="image" src="https://github.com/Jammini/TIL/assets/59176149/616dd563-2522-4740-8d40-c0bcaa461f03">

2. 미들웨어
    - MSA 인 경우, 처리율 제한 장치는 보통 API Gateway 에 구현한다.
    - API Gateway: 처리율 제한, SSL 종단, 사용자 인증, IP 허용 목록 관리 등

<img width="760" alt="image" src="https://github.com/Jammini/TIL/assets/59176149/8934e840-857f-4def-a519-a77392695f77">
**요약하면**

- 현재 기술 스택이 서버 측에 기능 구현이 가능한지 점검한다.
- 상황에 맞는 알고리즘 사용, 만약 제3 사업자가 제공하는 API Gateway 를 사용한다면 선택지는 제한이 될 수 있다.
- MSA 에 기반하고 있다면 인증, IP 허용 같은 기능을 이미 API Gateway 에 적용했을 수 있다. 그러면 처리율 제한도 API Gateway 에 포함하는 것이 좋다.
- 충분한 인력이 없다면 상용 솔루션도 고려해보는 것이 좋다.

### 처리율 제한 알고리즘

처리율 제한을 실현하는 알고리즘은 여러가지인데, 각기 다른 장단점을 갖고 있다.

- 토큰 버킷
- 누출버킷
- 고정 윈도 카운터
- 이동 윈도 로그
- 이동 윈도 카운터

### 개략적인 아키텍처

처리율 제한 알고리즘의 기본 아이디어는 단순하다. 얼마나 많은 요청이 접수되었는지를 추적할 수 있는 카운터를 추적 대상별로 두고(사용자별로 추적할 것인가? 아니면 IP주소별로? 아니면 API 엔드포인트나 서비스 단위로?)카운터의 값이 어떤 한도를 넘어서면 한도를 넘어 도착한 요청은 거부하는 것이다.

이 카운터는 레디스에 저장한다. 레디스는 빠른데다 시간에 기반한 만료정책을 지원한다.

<img width="673" alt="image" src="https://github.com/Jammini/TIL/assets/59176149/ea3e0257-8e14-4126-95c9-9a7656fb1475">

- 클라이언트가 처리율 제한 미들웨어에게 요청을 보낸다.
- 처리율 제한 미들웨어는 레디스의 지정 버킷에서 카운터를 가져와서 한도에 도달했는지 아닌지를 검사한다.
    - 한도에 도달했다면 요청은 거부된다.
    - 한도에 도달하지 않았다면 요청은 API서버로 전달된다. 한편 미들웨어는 카운터의 값을 증가시킨 후 다시 레디스에 저장한다.

## 3단계 상세 설계

개략적 설계를 봐서는 다음과 같은 사항은 알 수가 없다.

- 처리율 제한 규칙은 어떻게 만들어지고 어디에 저장되는가?
- 처리가 제한된 요청들은 어떻게 처리되는가?

### 처리율 제한 규칙

리프트(Lyft)는 처리율 제한에 오픈 소스를 사용하고 있다.

```
domain: messaging
descriptors:
  - key: message_type
    Value: marketing
    rate_limit:
        unit: day
        requests_per_unit: 5
```

위의 예시는 시스템이 처리할 수 있는 마케팅 메시지의 최대치를 하루 5개로 제한하고 있다. 이런 규칙들은 보통 설정 파일(configuration file) 형태로 디스크에 저장된다.

### 처리율 한도 초과 트래픽의 처리

어떤 요청이 한도 제한에 걸리면 API는 HTTP 429 응답을 클라이언트에게 보낸다.

**처리율 제한 장치가 사용하는 HTTP 헤더**

클라이언트가 자기 요청이 처리율 제한에 걸리고 있는지에 대한 정보를 아래 HTTP 헤더를 통해 전달한다.

- X-Ratelimit-Remaining: 윈도 내에 남은 처리 가능 요청의 수
- X-Ratelimit-Limit: 매 윈도마다 클라이언트가 전송할 수 있는 요청의 수
- X-Ratelimit-Retry-After: 한도 제한에 걸리지 않으려면 몇 초 뒤에 요청을 다시 보내야 하는지 알림

### 상세 설계

<img width="729" alt="image" src="https://github.com/Jammini/TIL/assets/59176149/c92f51a9-a330-446a-87d7-412006c8201c">

- 처리율 제한 규칙은 디스크에 보관한다. 작업 프로세스는 수시로 규칙을 디스크에서 읽어 캐시에 저장한다.
- 클라이언트가 요청을 서버에 보내면 요청은 먼저 처리율 제한 미들웨어에 도달한다.
- 처리율 제한 미들웨어는 제한 규칙을 캐시에서 가져온다. 아울러 카운터 및 마지막 요청의 타임스탬프를 레디스 캐시에서 가져온다. 가져온 값들에 근거하여 해당 미들웨어는 다음과 같은 결정을 내린다.
    - 해당 요청이 처리율 제한에 걸리지 않은 경우에는 API서버로 보낸다.
    - 해당 요청이 처리율 제한에 걸렸다면 429 에러를 클라이언트에 보낸다.

### 분산 환경에서의 처리율 제한 장치의 구현

여러대의 서버와 병렬 스레드를 지원하도록 시스템을 확장하기 위해 두가지 문제를 풀어야 한다.

- 경쟁 조건(race condition)
- 동기화(synchronization)

**경쟁 조건**

- 레디스에서 카운터의 값을 읽는다(counter)
- counter+1의 값이 임계치를 넘는지 본다
- 넘지 않는다면 레디스에 보관된 카운터 값을 1만큼 증가시킨다.

병행성이 심한 환경에서는 아래와 같은 경쟁 조건 이슈가 발생할 수 있다.

<img width="702" alt="image" src="https://github.com/Jammini/TIL/assets/59176149/3f8e8a5d-8370-4d3b-815e-3d90bfdf82c5">

가장 널리 알려진 해결책은 락(lock)이다. 하지만 락은 시스템의 성능을 상당히 떨어뜨린다는 문제가 있다.

락 대신 쓸 수 있는 해결책 두가지는 레디스 자료구조는 다음과 같다.

1. 루아 스크립트(Lua script)
2. 정렬 집합(sorted set)

**동기화 이슈**

분산 환경에서 고려해야 할 또 다른 중요한 요소다. 수백만 사용자를 지원하려면 한 대의 처리율 제한 장치 서버로는 충분하지 않을 수 있다.

고정 세션을 활용하여 클라이언트로부터의 요청은 항상 같은 처리율 제한 장치로 보낼 수 있도록 하는 방법도 있지만 규모면에서 확장 가능하거나 유연하지 않아 아래와 같은 레디스를 사용하는 것을 추천한다.

<img width="715" alt="image" src="https://github.com/Jammini/TIL/assets/59176149/0925784b-86e5-495f-b644-521aca2877d4">

**성능 최적화**

데이터센터에서 멀리 떨어진 사용자를 지원하려다 보면 지연시간(latency)이 증가할 수밖에 없다. 대부분의 클라우드 서비스 사업자는 세계 곳곳에 에지 서버(edge server)를 심어 놓는다. 사용자의 트래픽을 가장 가까운 에지 서버로 전달하여 지연시간을 줄인다.

두번째로 고려해야 할 것은 제한 장치간에 데이터를 동기화할 때 최종 일관성 모델을 사용하는 것이다. 

**모니터링**

처리율 제한 장치를 설치한 이후에는 효과적으로 동작하고 있는지 보기 위해 데이터를 모을 필요가 있다. 기본적으로 모니터링을 통해 확인하려는 것은 다음 두가지다.

- 채택된 처리율 제한 알고리즘이 효과적이다.
- 정의한 처리율 제한 규칙이 효과적이다.

## 4단계 마무리

- 경성(hard) 또는 연성(soft) 처리율 제한
    - 경성 처리율 제한 : 요청의 개수는 임계치를 절대 넘어설 수 없다.
    - 연성 처리율 제한: 요청 개수는 잠시 동안은 임계치를 넘어설 수 있다.
- 다양한 계층에서의 처리율 제한
    - 애플리케이션 계층(7번 계층)에서의 처리율 제한 외에도 다른 계층에서 제어
    - ex) Iptables를 사용하여 IP 주소에 처리율 제한을 적용
- 처리율 제한을 회피하는 방법
    - 클라이언트 측 캐시를 사용하여 API 호출 횟수 줄이기
    - 처리율 제한의 임계치를 이해하고, 짧은 시간 동안 너무 많은 메시지를 보내지 않도록 한다.
    - 예외나 에러를 처리하는 코드를 도입하여, 클라이언트가 예외적 상황으로부터 우아하게 복구될 수 있도록 한다.
        - 서버가 죽어서 안 되는건지, 요청이 많아서 안 되는 건지 클라에서 알 수 있도록 하자.
        - 에러를 받았을 때, 재처리 / 재시도 할 수 있도록 한다. 서킷 브레이커 사용하자.
    - 재시도(retry) 로직을 구현할 때는 충분한 백오프(back-off)시간을 둔다